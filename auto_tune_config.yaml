# Auto-tuning configuration (YOLOv11 + GPT-5)

llm:
  model: "gpt-5"
  system_prompt: |
    You are an expert ML engineer specializing in YOLOv11 object detection optimization.
    Analyze training/validation metrics and recommend concrete hyperparameter changes.
    Optimize F1 computed under FIXED evaluation thresholds (conf=0.01, iou=0.2).
    Safety constraint: do not reduce recall vs the current run unless clearly justified.
    Keep recommendations within valid ranges and use realistic step sizes.
  generation:
    max_new_tokens: 2000
    temperature: 0.3
    top_p: 0.9

  tuning_prompt_template: |
    You are an expert in YOLOv11 object detection optimization. Analyze results and recommend changes.

    METRICS SUMMARY (best epoch + final epoch):
    {metrics_summary}

    HISTORY (per-epoch or key checkpoints):
    {history_text}

    CURRENT CONFIG:
    {current_config}

    CONTEXT:
    - Task: Fire/Smoke detection (safety-critical; false negatives are most costly)
    - Dataset: train=18,946 images (13,133 original + 1,963 FN hard positives + 3,850 FP hard negatives)
    - Annotations: smoke=8,466, fire=527 (highly imbalanced)
    - Model: YOLOv11 anchor-free detector
    - Fixed evaluation (do not treat as tunable): conf=0.01, iou=0.2
    - Goal: maximize fixed-eval F1 while preserving/boosting recall

    TUNABLE HYPERPARAMETERS (valid ranges):
    - cls (0.1-2.0)
    - box (5.0-10.0)
    - dfl (1.0-2.0)
    - fl_gamma (0.0-2.0)
    - lr0 (1e-6 to 1e-3)
    - lrf (1e-6 to 1e-4)
    - weight_decay (0.0-0.001)
    - cos_lr (True/False)
    - hsv_h (0.0-0.1)
    - warmup_bias_lr (0.0-0.2)
    - mixup (0.0-0.3)
    - copy_paste (0.0-0.2)
    - mosaic (0.0-1.0)
    - scale (0.1-0.5)

    FIXED DEPLOYMENT PARAMETERS (not tunable):
    - nms_iou: 0.2 (fixed NMS threshold)
    - deploy_conf: 0.01 (fixed confidence threshold)

    TASK:
    1) Diagnose the limiting factor(s) using evidence from history (e.g., overfitting, underfitting, instability).
    2) Provide numeric values for ALL tunable parameters (14).
    3) Keep step sizes reasonable unless metrics strongly indicate otherwise.

    Respond in this EXACT format (no extra text):

    Analysis:
    [2-4 sentences. Must reference at least 2 concrete observations from history.]

    Recommended_Changes:
    cls: [value]
    box: [value]
    dfl: [value]
    fl_gamma: [value]
    lr0: [value]
    lrf: [value]
    weight_decay: [value]
    cos_lr: [true/false]
    hsv_h: [value]
    warmup_bias_lr: [value]
    mixup: [value]
    copy_paste: [value]
    mosaic: [value]
    scale: [value]

    Rationale:
    [2-4 sentences linking changes to precision/recall and imbalance.]

    Expected_Improvement:
    [Realistic F1 delta range (e.g., +0.02 to +0.06) and what would falsify this.]

training:
  epochs: 150
  timeout_seconds: 259200  # 72 hours (3 days) - safe buffer for 150 epochs
  results_csv_name: "results.csv"

  # Ranges used to validate/clip GPT recommendations (and for optional deployment tuning)
  hyperparameter_ranges:
    cls: [0.1, 2.0]
    box: [5.0, 10.0]
    dfl: [1.0, 2.0]
    fl_gamma: [0.0, 2.0]
    lr0: [1.0e-6, 1.0e-3]
    lrf: [1.0e-6, 1.0e-4]
    weight_decay: [0.0, 0.001]
    cos_lr: [true, false]
    hsv_h: [0.0, 0.1]
    warmup_bias_lr: [0.0, 0.2]
    mixup: [0.0, 0.3]
    copy_paste: [0.0, 0.2]
    mosaic: [0.0, 1.0]
    scale: [0.1, 0.5]
    # imgsz is now FIXED at 640 (not tunable)
    # nms_iou is now FIXED at 0.2 (not tunable)
    # deploy_conf is now FIXED at 0.01 (not tunable)

metrics:
  primary_metric: "f1_score"
  tracked_metrics:
    - precision
    - recall
    - f1_score
    - mAP50
    - mAP50_95
    - train_box_loss
    - train_cls_loss
    - train_dfl_loss
    - val_box_loss
    - val_cls_loss
    - val_dfl_loss

  # Ultralytics results.csv column mapping
  csv_columns:
    epoch: "epoch"
    precision: "metrics/precision(B)"
    recall: "metrics/recall(B)"
    mAP50: "metrics/mAP50(B)"
    mAP50_95: "metrics/mAP50-95(B)"
    train_box_loss: "train/box_loss"
    train_cls_loss: "train/cls_loss"
    train_dfl_loss: "train/dfl_loss"
    val_box_loss: "val/box_loss"
    val_cls_loss: "val/cls_loss"
    val_dfl_loss: "val/dfl_loss"

trend_analysis:
  enabled: true
  early_epochs: 10
  late_epochs: 10
  plateau_threshold: 0.005
  plateau_epochs: 20

output:
  history_filename: "tuning_history.json"
  log_level: "INFO"          # DEBUG, INFO, WARNING, ERROR
  save_llm_responses: true
  save_metrics_plots: false  # optional / future

dataset:
  name: "Fire_data_v3_with_hard_examples_cleaned"
  splits:
    total_images: 19963
    train_images: 18946
    test_images: 1017

  # Annotation counts (not image counts)
  annotations:
    smoke: 8466
    fire: 527

  train_composition:
    original_images: 13133
    hard_positives_fn: 1963
    hard_negatives_fp: 3850
    total_train_images: 18946

defaults:
  model_variant: "11x"
  initial_config: "balanced"
  iterations: 50
  batch_size: 128  # Note: Auto-tuning uses adaptive batch sizing based on imgsz
                   # ≤640: batch=128, ≤1024: batch=64, >1024: batch=32
  imgsz: 640       # FIXED - not tunable by GPT-5
  nms_iou: 0.2     # FIXED - NMS threshold for deployment
  deploy_conf: 0.01  # FIXED - confidence threshold for deployment
  device: "0,1"
